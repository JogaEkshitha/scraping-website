Job Market Analysis Using Web Scraping & Data Visualization

Project Overview
This project aims to understand the changing job market by collecting and analyzing job listings from Naukri.com. It uses web scraping, data cleaning, and data visualization techniques to identify key insights such as in-demand roles, required skills, salary ranges, and top hiring cities. The goal is to help job seekers, training centers, and employers make informed decisions.

Tools & Technologies Used

Web Scraping:

Selenium – for handling dynamic content and navigating through pages

Beautiful Soup – for extracting job-related details from HTML content

Data Analysis:

Pandas – for cleaning, organizing, and exploring data

NumPy – for numerical operations and calculations

Visualization & Dashboarding:

Matplotlib & Seaborn – for static data visualization

Google Looker Studio – for building interactive dashboards

Code Platforms:

Google Colab – for cloud-based coding and testing

VS Code – for local development


Project Workflow

Data Collection:
Job listings were scraped from Naukri.com, capturing details like:

Job Title

Company Name

Location

Experience Required

Salary Range

Key Skills

Data Cleaning:

Removed duplicates and missing values

Standardized formats for analysis

Exploratory Data Analysis (EDA):

Analyzed trends in job roles, skills, locations, and salaries

Identified top hiring cities and most demanded technologies

Dashboard Creation:

Built interactive and visual dashboards using Google Looker Studio

Enabled filtering based on roles, location, experience, and salary

Key Insights

Most in-demand job roles and skills

Salary trends by city and experience

Popular job locations and companies

Useful for career planning and recruitment strategies

